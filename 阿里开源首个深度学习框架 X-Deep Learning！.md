# 阿里开源首个深度学习框架 X-Deep Learning！
<div style="text-align:center" align="center">
<img src="/images/深度学习框架1.png" align="center" />
</div>
刚刚，阿里妈妈正式对外发布了X-Deep Learning(下文简称XDL)的开源代码地址，开发者们可以在Github上自主下载。

Github地址：https://github.com/alibaba/x-deeplearning

此前，在11月底，阿里妈妈就公布了这项开源计划，引来了业界的广泛关注。XDL突破了现有深度学习开源框架大都面向图像、语音等低维稠密数据而设计的现状，面向高维稀疏数据场景进行了深度优化，并已大规模应用于阿里妈妈的业务及生产场景。本文将为大家详细介绍XDL的设计理念及关键技术。

<h3>概述</h3>
以深度学习为核心的人工智能技术，过去的几年在语音识别、计算机视觉、自然语言处理等领域获得了巨大的成功，其中以GPU为代表的硬件计算力，以及优秀的开源深度学习框架起到了巨大的推动作用。

尽管以TensorFlow、PyTorch、MxNet等为代表的开源框架已经取得了巨大的成功，但是当我们把深度学习技术应用在广告、推荐、搜索等大规模工业级场景时，发现这些框架并不能很好的满足我们的需求。矛盾点在于开源框架大都面向图像、语音等低维连续数据设计，而互联网的众多核心应用场景（如广告/推荐/搜索）往往面对的是高维稀疏离散的异构数据，参数的规模动辄百亿甚至千亿。进一步的，不少产品应用需要大规模深度模型的实时训练与更新，现有开源框架在分布式性能、计算效率、水平扩展能力以及实时系统适配性的等方面往往难以满足工业级生产应用的需求。

X-DeepLearning正是面向这样的场景设计与优化的工业级深度学习框架，经过阿里巴巴广告业务的锤炼，XDL在训练规模和性能、水平扩展能力上都表现出色，同时内置了大量的面向广告/推荐/搜索领域的工业级算法解决方案。

<h4>系统核心能力</h4>
1.  为高维稀疏数据场景而生。支持千亿参数的超大规模深度模型训练，支持批学习、在线学习等模式。

2. 工业级分布式训练能力。支持CPU/GPU的混合调度，具备完整的分布式容灾语义，系统的水平扩展能力优秀，可以轻松做到上千并发的训练。

3. 高效的结构化压缩训练。针对互联网样本的数据特点，提出了结构化计算模式。典型场景下，相比传统的平铺样本训练方式，样本存储空间、样本IO效率、训练绝对计算量等方面都大幅下降，推荐等场景下整体训练效率最大可提升10倍以上。

4.  成熟多后端支持。单机内部的稠密网络计算复用了成熟开源框架的能力，只需要少量的分布式驱动代码修改，就可以把TensorFlow/MxNet等的单机代码运行在XDL上，获得XDL分布式训练与高性能稀疏计算的能力。

<h4>内置工业级算法解决方案</h4>
1）点击率预估领域的最新算法，包括深度兴趣网络（Deep Interest Network, DIN），用户兴趣演化模型（Deep Interest Evolution Network, DIEN），跨媒介网络（Cross Media Network，CMN)。

2）点击率&转化率联合建模的全空间多任务模型（Entire Space Multi-task Model， ESMM）。

3）匹配召回领域的最新算法——深度树匹配模型（Tree-based Deep Match，TDM）。

4）轻量级通用模型压缩算法（Rocket Training）

<h3>系统设计与优化</h3>
<div style="text-align:center" align="center">
<img src="/images/深度学习框架2.png" align="center" />
</div>

<h4>XDL-Flow：数据流与分布式运行时</h4>
XDL-Flow驱动整个深度学习计算图的生成与执行，包括样本流水线、稀疏表征学习、稠密网络学习。同时，XDL-Flow也负责分布式模型的存储与交换控制逻辑，分布式容灾与恢复控制等全局一致性协调的工作。

在搜索、推荐、广告等场景下的样本量巨大，通常达到几十TB至数百TB，如果不能很好的优化样本流水线，样本IO系统很容易成为整个系统的瓶颈，从而导致计算硬件的利用率低下。在大规模稀疏场景下，样本读取的特点是IO密集，稀疏表征计算的特点是参数交换网络通信密集，稠密深度计算是计算密集型。

XDL-Flow通过把三个主要环节异步流水线并行，较好的适配了3种不同类型任务的性能。最好的情况下，前两个阶段的延时都被隐藏了。同时，我们也正在尝试自动化的Tunning异步流水线的各个参数，包括各个Step的并行度、Buffer大小等，尽可能让用户不需要关心整个异步流水线并行的细节。
<div style="text-align:center" align="center">
<img src="/images/深度学习框架3.png" align="center" />
</div>

<h4>AMS：高效模型服务器</h4>
AMS是面向稀疏场景专门设计与优化的分布式模型存储与交换子系统。我们综合小包网络通信、参数存储结构、参数分布式策略等进行了大量的软硬件优化，使得AMS在吞吐力和水平扩展力上都大幅优于传统的Parameter Server，AMS也支持内置的深度网络计算，使得你可以使用AMS进行表征子网络的二阶计算。

1）AMS通过软硬件结合在网络通信层做了大量优化，包括使用Seastar，DPDK，CPUBind，ZeroCopy等技术，充分压榨硬件性能，经过我们实际测试，大规模并发训练下，参数交换导致的小包吞吐能力是传统RPC框架的5倍以上。

2）通过内置的参数动态均衡策略，可以在运行过程中找到最优的稀疏参数分布策略，有效解决传统参数服务器由于参数分布式不均匀带来的热点问题，大幅提高了系统在高并发情况下的水平扩展能力。

3）AMS同样支持通过GPU加速大Batch Size场景下的Sparse Embedding计算，针对超大Batch的场景，可以起到很好的加速作用。

4）AMS支持内部定义子网络。例如我们的算法解决方案中提供的Cross-Media建模，图像部分的表征子网络就是以AMS内运行的方式定义的，大幅减少了重复计算和网络吞吐。

<h4>Backend Engine：桥接技术复用成熟框架的单机能力</h4>
为了充分利用现有开源深度学习框架在稠密深度网络上的能力，XDL使用桥接技术（Bridging），把开源深度学习框架（本期开源版XDL支持了TensorFlow、MxNet）作为我们的单机稠密网络的计算引擎后端。用户可以在保留TensorFlow或MxNet网络开发习惯的同时，通过少量的驱动代码修改，就直接获得XDL在大规模稀疏计算上的分布式训练能力。换句话说，使用XDL时无需再学习一门新的框架语言，这带来另一个好处是XDL可以跟现有成熟的开源社区无缝对接——用户可以很轻松地将tensorflow社区的某个开源模型通过XDL拓展到工业级场景。

<h4>Compact Computation：结构化计算模式大幅提升训练效率</h4>
工业界稀疏场景下的样本表征，往往呈现很强的结构化特点，例如用户特征、商品特征、场景特征。这种构建方式决定了某些特征会大量出现在重复的样本中——隶属于同一个用户的多条样本中，用户特征很大一部分是相同的。结构化样本压缩正是利用海量样本中，大量局部特征重复这一特点,在存储和计算两个维度上对特征进行压缩，节省了存储、计算和通信带宽资源。样本预处理阶段，对需要聚合的特征进行排序（例如按用户ID排序，聚合用户特征）；batching阶段，在tensor层面进行压缩；计算阶段，压缩特征只有在最后一层才会展开，极大节省深层网络的计算开销。 推荐场景下的效果验证表示，在典型的生产数据上，使用聚合排序的样本和完全shuffle的样本评估AUC指标一致，整体性能提升10倍以上。
<div style="text-align:center" align="center">
<img src="/images/深度学习框架4.png" align="center" />
</div>

<h4>Online-Learning：大规模在线学习</h4>
在线学习近年来在工业界开始被大规模应用，它是工程与算法的深入结合，赋予模型实时捕捉线上流量变化的能力，在一些对时效性要求很高的场景，有十分大的价值。例如在电商大促等场景下，在线学习可以更加实时的捕捉用户行为的变化，显著的提升模型的实时效果。XDL提供了一套完整的在线学习的解决方案，支持基于全量模型，读取实时消息队列里的样本进行实时持续学习，我们内置支持了Kafka等作为Message Source，并允许按照用户设置控制模型写出的周期。另外，为了避免无限制的新特征流入导致的实时模型爆炸问题，XDL内置了实时特征自动选择与过期特征淘汰等功能，保证用户使用XDL进行在线学习的简便性。

1）去ID化的稀疏特征学习：传统的机器学习框架一般要求对稀疏特征进行ID化表征（从0开始紧凑编码），以此来保证训练的高效性。XDL则允许直接以原始的特征进行训练，大幅简化了特征工程的复杂度，极大地增加了全链路数据处理效率，这一特性在实时在线学习场景下显得更加有意义。

2）实时特征频控：用户可以设置一个特征过滤的阈值，例如出现次数大于N次的特征才纳入模型训练，系统会自动的采用自动概率丢弃的算法进行特征选择，这样可以大幅降低无效超低频特征在模型中的空间占用。

3）过期特征淘汰：长周期的在线学习时，用户也可以通过打开过期特征淘汰功能，系统会自动的对影响力弱且长周期没有碰触到的特征参数进行自动淘汰。

<h3>X-DeepLearning算法解决方案</h3>
<h4>典型的点击率(Click-Through Rate)预估模型</h4>
DIN（Deep Interest Network）

传统的Embedding&MLP类的模型并未对用户的表达做过多的工作。往往通过embedding的机制将用户的历史行为投影到一个定长的向量空间，再经过一个sum/avg pooling操作得到一个定长的用户向量表达。但是用户的兴趣是多种多样的，用一个固定的向量去表达用户不同的兴趣是非常难的。事实上用户在面对不同商品的时候，其兴趣表现也不一样，仅仅和这个商品相关的兴趣会影响用户的决策。

因此我们在预估用户对一个具体商品的点击率的时候只需要表达其与此商品相关的兴趣。在DIN中我们提出了一个兴趣激活机制，通过被预估的商品去激活用户历史行为中相关的部分，从而获取用户在这个具体商品上的兴趣。

论文地址：https://arxiv.org/abs/1706.06978

DIEN（Deep Interest Evolution Network）

DIEN主要解决两个问题：兴趣提取和兴趣演化。在兴趣提取这部分，传统的算法直接将用户的历史行为当做用户的兴趣。同时整个建模过程中的监督信息全部集中于广告点击样本上。而单纯的广告点击样本只能体现用户在决策是否点击广告时的兴趣，很难建模好用户历史每个行为时刻的兴趣。

本文中我们提出了auxiliary loss 用于兴趣提取模块，约束模型在对用户每一个历史行为时刻的隐层表达能够推测出后续的行为，我们希望这样的隐层表达能更好的体现用户在每一个行为时刻的兴趣。在兴趣提取模块后我们提出了兴趣演化模块，传统的RNN类似的方法只能建模一个单一的序列，然而在电商场景 用户不同的兴趣其实有不同的演化过程。在本文中我们提出AUGRU（Activation Unit GRU），让GRU的update门和预估的商品相关。在建模用户的兴趣演化过程中，AUGRU会根据不同的预估目标商品构建不同的兴趣演化路径，推断出用户和此商品相关的兴趣。

论文地址：https://arxiv.org/abs/1809.03672

CMN（Cross Media Network）

CMN旨在CTR预估模型中引入更多的模态数据，如图像信息。在原有ID类特征基础上，增加了图像视觉特征，共同加入广告CTR预估模型，在阿里妈妈大规模数据上取得了显著的效果提升。CMN包括多项技术特色：第一，图像内容特征抽取模型与主模型共同训练，联合优化； 第二，同时使用图像信息表达广告和用户，其中用户表达采用用户历史行为对应的图片； 第三，为处理训练涉及到的海量图像数据，提出了“高级模型服务”的计算范式，有效减少训练过程中的计算、通信、存储负载。CMN除用于图像特征引入外，对于文本、视频等内容特征也可以以合适的特征提取网络、用同样的模型处理。

论文地址：https://arxiv.org/abs/1711.06505

<h4>典型的转化率(Conversion Rate)预估模型</h4>
ESMM（Entire Space Multi-task Model）

Entire Space Multi-task Model (ESMM) 是阿里妈妈研发的新型多任务联合训练算法范式。ESMM模型首次提出了利用学习CTR和CTCVR的辅助任务迂回学习CVR的思路，利用用户行为序列数据在完整样本空间建模，避免了传统CVR模型经常遭遇的样本选择偏差和训练数据稀疏的问题，取得了显著的效果。

ESMM 可以很容易地推广到具有序列依赖性的用户行为(浏览、点击、加购、购买等)预估中，构建全链路多目标预估模型。ESMM模型中的BASE子网络可以替换为任意的学习模型，因此ESMM的框架可以非常容易地和其他学习模型集成，从而吸收其他学习模型的优势，进一步提升学习效果，想象空间巨大。

论文地址：https://arxiv.org/abs/1804.07931

<h4>典型的匹配召回模型</h4>
TDM（Tree-based Deep Match）

TDM自主创新提出了一套完整的基于树的复杂深度学习推荐匹配算法框架，它通过建立用户兴趣层次树结构实现了高效的全库检索，并以此为基础赋能深度模型引入Attention等更先进的计算结构，达到了在精度、召回率以及新颖性等指标上相对于传统推荐方法的显著效果提升。

进一步的，TDM设计实现了一套完整的 初始树-模型训练-树重建-模型再训练 的联合训练迭代框架，更加促进了效果的提升。联合训练赋予了TDM算法框架较好的通用性，为TDM向新场景、新领域的迁移扩展提供了良好的理论基础和极大的工程可行性。

论文地址：https://arxiv.org/abs/1801.02294

<h4>典型的模型压缩算法</h4>
Rocket Training

工业上在线模型的实时推理对响应时间提出非常严苛的要求，从而一定程度上限制了模型的复杂程度。模型复杂程度的受限可能会导致模型学习能力的降低从而带来效果的下降。

目前有2种思路来解决这个问题：一方面，可以在固定模型结构和参数的情况下，用计算数值压缩来降低inference时间，同时也有设计更精简的模型以及更改模型计算方式的工作，如Mobile Net和ShuffleNet等工作。

另一方面，利用复杂的模型来辅助一个精简模型的训练，测试阶段，利用学习好的小模型来进行推理。这两种方案并不冲突，在大多数情况下第二种方案可以通过第一种方案进一步降低inference时间，同时，考虑到相对于严苛的在线响应时间，我们有更自由的训练时间，有能力训练一个复杂的模型。Rocket Training属于第二种思路，它比较的轻巧优雅，方法具有很强的通用性，可以根据系统能力来定制模型复杂度，提供了一种"无极调速"手段。在阿里妈妈的生产实践中，Rocket Training可以极大地节省在线计算资源，显著提升系统应对双十一大促等流量洪峰的能力。

论文地址：https://arxiv.org/abs/1708.04106

<h3>BenchMark</h3>
我们提供几组Benchmark数据供大家参考，重点看一下XDL在大batch、小batch等场景下的训练性能以及水平可扩展能力，以及结构化压缩训练带来的提速。

<h4>基于CPU训练的深度CTR模型</h4>
我们选取模型结构为Sparse Embedding DNN结构，N路Sparse特征分别做Embedding，再通过BiInteraction得到若干路NFM特征。选择两个特征规模的场景，Sparse特征总规模分别约为10亿（对应百亿参数）/100亿（对应千亿参数），dense维度为数百维，单条样本Sparse特征id数量约100+/300+个。

训练模式：BatchSize=100，异步SGD训练。

从bechmark结果可以看到，在高维稀疏场景下，XDL有明显的优势，在相当大并发的情况下，保持了良好的线性可扩展能力。

<div style="text-align:center" align="center">
<img src="/images/深度学习框架5.png" align="center" />
</div>
基于GPU训练的深度CTR模型

<div style="text-align:center" align="center">
<img src="/images/深度学习框架8.png" align="center" />
</div>
